import Foundation
import WhisperKit
import AVFoundation

@MainActor
class WhisperService: ObservableObject {
    @Published var subtitles: [Subtitle] = []
    @Published var isProcessing = false
    @Published var processingProgress: String = ""
    @Published var fullTranscript = ""
    @Published var error: String?
    @Published var isModelLoaded = false
    @Published var hasPreprocessedSubtitle = false
    @Published var isStreamingMode = false
    @Published var streamingReady = false  // æµå¼æ¨¡å¼å‡†å¤‡å¥½å¯ä»¥æ’­æ”¾
    
    var currentTranscription: String {
        subtitles.map { $0.text }.joined(separator: "\n")
    }
    
    private var whisperKit: WhisperKit?
    private var currentTask: Task<Void, Never>?
    private var streamingTask: Task<Void, Never>?
    private var currentAudioURL: URL?
    private var currentModelId: String = "large-v3"
    
    // æµå¼å¤„ç†ç›¸å…³
    private var processedEndTime: TimeInterval = 0  // å·²å¤„ç†åˆ°çš„æ—¶é—´ç‚¹
    private var pendingPolishText: String = ""      // å¾…æ¶¦è‰²çš„æ–‡æœ¬ç¼“å†²
    private var pendingPolishSubtitles: [Subtitle] = []  // å¾…æ¶¦è‰²çš„å­—å¹•
    private let chunkDuration: TimeInterval = 30    // æ¯ä¸ªchunk 30ç§’
    private let overlapDuration: TimeInterval = 3   // é‡å 3ç§’é¿å…è¾¹ç•Œé—®é¢˜
    private let preloadDuration: TimeInterval = 60  // é¢„åŠ è½½60ç§’
    
    private var modelDirectory: URL {
        let appSupport = FileManager.default.urls(for: .applicationSupportDirectory, in: .userDomainMask).first!
        return appSupport.appendingPathComponent("HistoryPodcastPlayer/WhisperModels")
    }
    
    private var whisperKitModelDirectory: URL {
        modelDirectory.appendingPathComponent("models/argmaxinc/whisperkit-coreml")
    }
    
    private var subtitleDirectory: URL {
        let appSupport = FileManager.default.urls(for: .applicationSupportDirectory, in: .userDomainMask).first!
        return appSupport.appendingPathComponent("HistoryPodcastPlayer/Subtitles")
    }
    
    init() {
        NotificationCenter.default.addObserver(forName: .whisperModelChanged, object: nil, queue: .main) { [weak self] notification in
            if let modelId = notification.object as? String {
                Task { @MainActor in self?.switchModel(to: modelId) }
            }
        }
        Task { await loadModel() }
    }

    
    private func subtitlePath(for audioURL: URL) -> URL {
        let fileName = audioURL.deletingPathExtension().lastPathComponent
        // ä½¿ç”¨ç¨³å®šçš„ hashï¼ˆåŸºäºæ–‡ä»¶åï¼Œè·¨ä¼šè¯ä¸€è‡´ï¼‰
        let hash = stableHash(audioURL.lastPathComponent)
        return subtitleDirectory.appendingPathComponent("\(fileName)_\(abs(hash)).srt")
    }
    
    /// ç¨³å®šçš„ hash å‡½æ•°ï¼ˆè·¨ä¼šè¯ä¸€è‡´ï¼Œä¸ä½¿ç”¨ Swift çš„ hashValueï¼‰
    private func stableHash(_ string: String) -> Int {
        var hash = 5381
        for char in string.utf8 {
            hash = ((hash << 5) &+ hash) &+ Int(char)
        }
        return hash
    }
    
    func hasSubtitle(for audioURL: URL) -> Bool {
        // å…ˆæ£€æŸ¥æ–°æ ¼å¼ï¼ˆç¨³å®š hashï¼‰
        if FileManager.default.fileExists(atPath: subtitlePath(for: audioURL).path) {
            return true
        }
        // å…¼å®¹æ—§æ ¼å¼ï¼ˆä¸ç¨³å®š hashï¼‰- å°è¯•æŸ¥æ‰¾åŒ¹é…çš„æ–‡ä»¶
        return findLegacySubtitle(for: audioURL) != nil
    }
    
    /// æŸ¥æ‰¾æ—§æ ¼å¼çš„å­—å¹•æ–‡ä»¶ï¼ˆå…¼å®¹ä¹‹å‰ä½¿ç”¨ä¸ç¨³å®š hash ä¿å­˜çš„æ–‡ä»¶ï¼‰
    private func findLegacySubtitle(for audioURL: URL) -> URL? {
        let fileName = audioURL.deletingPathExtension().lastPathComponent
        let fm = FileManager.default
        
        // ç¡®ä¿ç›®å½•å­˜åœ¨
        if !fm.fileExists(atPath: subtitleDirectory.path) {
            return nil
        }
        
        guard let contents = try? fm.contentsOfDirectory(at: subtitleDirectory, includingPropertiesForKeys: nil) else {
            return nil
        }
        
        // æŸ¥æ‰¾ä»¥æ–‡ä»¶åå¼€å¤´çš„ .srt æ–‡ä»¶ï¼Œä¼˜å…ˆè¿”å›æœ€æ–°çš„
        var matchingFiles: [URL] = []
        for file in contents {
            if file.pathExtension == "srt" && file.lastPathComponent.hasPrefix(fileName + "_") {
                matchingFiles.append(file)
            }
        }
        
        // å¦‚æœæœ‰å¤šä¸ªåŒ¹é…ï¼Œè¿”å›æœ€æ–°ä¿®æ”¹çš„é‚£ä¸ª
        if matchingFiles.count > 1 {
            let sorted = matchingFiles.sorted { url1, url2 in
                let date1 = (try? fm.attributesOfItem(atPath: url1.path)[.modificationDate] as? Date) ?? Date.distantPast
                let date2 = (try? fm.attributesOfItem(atPath: url2.path)[.modificationDate] as? Date) ?? Date.distantPast
                return date1 > date2
            }
            return sorted.first
        }
        
        return matchingFiles.first
    }
    
    func loadSavedSubtitle(for audioURL: URL) -> Bool {
        // å…ˆå°è¯•æ–°æ ¼å¼
        var path = subtitlePath(for: audioURL)
        print("ğŸ” å°è¯•åŠ è½½å­—å¹•: \(path.lastPathComponent)")
        
        if !FileManager.default.fileExists(atPath: path.path) {
            print("ğŸ” æ–°æ ¼å¼ä¸å­˜åœ¨ï¼Œå°è¯•æ—§æ ¼å¼...")
            // å°è¯•æ—§æ ¼å¼
            if let legacyPath = findLegacySubtitle(for: audioURL) {
                print("ğŸ” æ‰¾åˆ°æ—§æ ¼å¼å­—å¹•: \(legacyPath.lastPathComponent)")
                path = legacyPath
            } else {
                print("ğŸ” æ²¡æœ‰æ‰¾åˆ°ä»»ä½•å­—å¹•æ–‡ä»¶")
                return false
            }
        }
        
        guard let content = try? String(contentsOf: path, encoding: .utf8) else {
            print("âŒ æ— æ³•è¯»å–å­—å¹•æ–‡ä»¶å†…å®¹")
            return false
        }
        subtitles = parseSRT(content)
        fullTranscript = subtitles.map { $0.text }.joined(separator: " ")
        hasPreprocessedSubtitle = true
        print("âœ… æˆåŠŸåŠ è½½å­—å¹•ï¼Œå…± \(subtitles.count) æ¡")
        return true
    }
    
    func startTranscription(audioURL: URL) {
        currentAudioURL = audioURL
        subtitles = []
        fullTranscript = ""
        hasPreprocessedSubtitle = false
        
        if loadSavedSubtitle(for: audioURL) {
            processingProgress = "å·²åŠ è½½ä¿å­˜çš„å­—å¹•"
            return
        }
        startFullTranscription(audioURL: audioURL)
    }
    
    func startFullTranscription(audioURL: URL, forceTranscribe: Bool = false) {
        currentTask?.cancel()
        currentTask = Task {
            // ç¡®ä¿æ— è®ºå¦‚ä½•éƒ½ä¼šé‡ç½® isProcessing
            defer {
                Task { @MainActor in
                    self.isProcessing = false
                }
            }
            
            if !isModelLoaded || whisperKit == nil { await loadModel() }
            guard let whisper = whisperKit else { error = "æ¨¡å‹æœªåŠ è½½"; return }
            
            isProcessing = true
            error = nil
            subtitles = []
            fullTranscript = ""
            hasPreprocessedSubtitle = false
            
            do {
                let asset = AVURLAsset(url: audioURL)
                let duration = try await asset.load(.duration)
                let totalDuration = CMTimeGetSeconds(duration)
                processingProgress = "è½¬å†™ä¸­ï¼ˆ\(formatTime(totalDuration))ï¼‰..."
                print("ğŸ¤ å¼€å§‹ Whisper è½¬å†™ï¼ŒéŸ³é¢‘æ—¶é•¿: \(formatTime(totalDuration))")
                
                let options = DecodingOptions(task: .transcribe, language: "zh", usePrefillPrompt: true, skipSpecialTokens: true, withoutTimestamps: false, wordTimestamps: true)
                
                // æ·»åŠ è¶…æ—¶ä¿æŠ¤
                let transcribeTask = Task {
                    try await whisper.transcribe(audioPath: audioURL.path, decodeOptions: options)
                }
                
                let results: [TranscriptionResult]
                do {
                    results = try await transcribeTask.value
                    print("ğŸ¤ Whisper è½¬å†™å®Œæˆï¼Œè·å¾— \(results.count) ä¸ªç»“æœ")
                } catch {
                    print("âŒ Whisper è½¬å†™å‡ºé”™: \(error)")
                    throw error
                }
                
                guard !Task.isCancelled else { return }
                
                var rawSubtitles: [Subtitle] = []
                var rawText = ""
                for result in results {
                    for segment in result.segments {
                        var text = segment.text.trimmingCharacters(in: .whitespacesAndNewlines)
                        if !text.isEmpty {
                            text = convertToSimplified(text)
                            rawSubtitles.append(Subtitle(text: text, startTime: TimeInterval(segment.start), endTime: TimeInterval(segment.end)))
                            rawText += text
                        }
                    }
                }
                
                guard !Task.isCancelled else { return }
                
                print("ğŸ“ è½¬å†™å®Œæˆï¼ŒåŸå§‹æ–‡æœ¬é•¿åº¦: \(rawText.count) å­—ç¬¦")
                processingProgress = "AI æ¶¦è‰²ä¸­..."
                let polishedText = await polishWithOllama(rawText)
                print("âœ… æ¶¦è‰²å®Œæˆï¼Œç»“æœé•¿åº¦: \(polishedText?.count ?? 0) å­—ç¬¦")
                
                guard !Task.isCancelled else { return }
                
                subtitles = redistributeTimestamps(polishedText: polishedText ?? rawText, originalSubtitles: rawSubtitles)
                fullTranscript = subtitles.map { $0.text }.joined(separator: " ")
                
                await saveSubtitle(for: audioURL)
                processingProgress = "è½¬å†™å®Œæˆå¹¶å·²ä¿å­˜"
                hasPreprocessedSubtitle = true
            } catch {
                if !Task.isCancelled { self.error = "è½¬å†™å¤±è´¥: \(error.localizedDescription)" }
            }
        }
    }

    
    private func polishWithOllama(_ text: String) async -> String? {
        // å¦‚æœæ–‡æœ¬å¤ªé•¿ï¼Œåˆ†æ®µå¤„ç†ï¼ˆæ¯æ®µçº¦1500å­—ç¬¦ï¼Œå¤„ç†æ›´å¿«ï¼‰
        let maxChars = 1500
        if text.count > maxChars {
            return await polishLongText(text, maxChars: maxChars)
        }
        
        return await polishSegment(text)
    }
    
    private func polishLongText(_ text: String, maxChars: Int) async -> String? {
        // æŒ‰å­—ç¬¦æ•°åˆ†å‰²
        var segments: [String] = []
        var current = ""
        
        for char in text {
            current.append(char)
            if current.count >= maxChars {
                segments.append(current)
                current = ""
            }
        }
        if !current.isEmpty {
            segments.append(current)
        }
        
        print("ğŸ“ æ–‡æœ¬åˆ†ä¸º \(segments.count) æ®µè¿›è¡Œæ¶¦è‰²")
        
        var results: [String] = []
        for (i, segment) in segments.enumerated() {
            processingProgress = "AI æ¶¦è‰²ä¸­ (\(i+1)/\(segments.count))..."
            print("ğŸ”„ æ¶¦è‰²ç¬¬ \(i+1)/\(segments.count) æ®µ...")
            if let polished = await polishSegment(segment) {
                results.append(polished)
                print("âœ… ç¬¬ \(i+1) æ®µæ¶¦è‰²å®Œæˆ")
            } else {
                results.append(segment) // å¤±è´¥æ—¶ä¿ç•™åŸæ–‡
                print("âš ï¸ ç¬¬ \(i+1) æ®µæ¶¦è‰²å¤±è´¥ï¼Œä¿ç•™åŸæ–‡")
            }
        }
        
        return results.joined(separator: "\n")
    }
    
    private func polishSegment(_ text: String) async -> String? {
        // ä¼˜å…ˆä½¿ç”¨ LM Studio (MLX)ï¼Œå¦‚æœå¤±è´¥åˆ™å›é€€åˆ° Ollama
        if let result = await polishWithLMStudio(text) {
            return result
        }
        return await polishWithOllamaAPI(text)
    }
    
    private func polishWithLMStudio(_ text: String) async -> String? {
        print("ğŸ”„ å¼€å§‹ LM Studio æ¶¦è‰²ï¼Œè¾“å…¥é•¿åº¦: \(text.count)")
        
        let url = URL(string: "http://127.0.0.1:1234/v1/chat/completions")!
        var request = URLRequest(url: url)
        request.httpMethod = "POST"
        request.setValue("application/json", forHTTPHeaderField: "Content-Type")
        request.timeoutInterval = 180 // 3åˆ†é’Ÿè¶…æ—¶
        
        // ä½¿ç”¨ç”¨æˆ·é…ç½®çš„æ¶¦è‰²æç¤ºè¯
        let polishTemplate = await AppSettings.shared.polishPrompt
        let prompt = polishTemplate.replacingOccurrences(of: "{{TRANSCRIPT}}", with: text)
        
        let messages: [[String: String]] = [
            ["role": "user", "content": prompt]
        ]
        
        let body: [String: Any] = [
            "model": "qwen/qwen3-8b",
            "messages": messages,
            "temperature": 0.1,
            "max_tokens": 8000
        ]
        
        do {
            request.httpBody = try JSONSerialization.data(withJSONObject: body)
            
            let config = URLSessionConfiguration.default
            config.timeoutIntervalForRequest = 180
            config.timeoutIntervalForResource = 180
            let session = URLSession(configuration: config)
            
            print("ğŸ“¤ å‘é€è¯·æ±‚åˆ° LM Studio...")
            let (data, response) = try await session.data(for: request)
            print("ğŸ“¥ æ”¶åˆ° LM Studio å“åº”")
            
            guard let httpResponse = response as? HTTPURLResponse else {
                print("âŒ LM Studio: æ— æ•ˆå“åº”")
                return nil
            }
            
            if httpResponse.statusCode != 200 {
                print("âŒ LM Studio: HTTP \(httpResponse.statusCode)")
                if let errorStr = String(data: data, encoding: .utf8) {
                    print("   é”™è¯¯è¯¦æƒ…: \(errorStr.prefix(500))")
                }
                return nil
            }
            
            if let json = try JSONSerialization.jsonObject(with: data) as? [String: Any],
               let choices = json["choices"] as? [[String: Any]],
               let first = choices.first,
               let message = first["message"] as? [String: Any] {
                
                var result: String? = nil
                
                if let content = message["content"] as? String, !content.isEmpty {
                    result = content
                } else if let reasoning = message["reasoning"] as? String, !reasoning.isEmpty {
                    result = reasoning
                }
                
                if var text = result?.trimmingCharacters(in: .whitespacesAndNewlines), !text.isEmpty {
                    // ç§»é™¤ Qwen3 çš„ <think></think> æ ‡ç­¾
                    if let thinkEnd = text.range(of: "</think>") {
                        text = String(text[thinkEnd.upperBound...]).trimmingCharacters(in: .whitespacesAndNewlines)
                    }
                    if !text.isEmpty {
                        print("âœ… LM Studio æ¶¦è‰²æˆåŠŸï¼Œè¿”å› \(text.count) å­—ç¬¦")
                        return text
                    }
                }
                print("âš ï¸ LM Studio è¿”å›ç©ºå†…å®¹")
            }
        } catch {
            print("âŒ LM Studioæ¶¦è‰²å¤±è´¥: \(error.localizedDescription)")
        }
        return nil
    }
    
    private func polishWithOllamaAPI(_ text: String) async -> String? {
        let url = URL(string: "http://localhost:11434/api/generate")!
        var request = URLRequest(url: url)
        request.httpMethod = "POST"
        request.setValue("application/json", forHTTPHeaderField: "Content-Type")
        request.timeoutInterval = 120
        
        let prompt = """
        è¯·æ ¡å¯¹ä»¥ä¸‹è¯­éŸ³è½¬å†™æ–‡æœ¬ï¼Œæ·»åŠ æ ‡ç‚¹ç¬¦å·ï¼Œä¿®æ­£é”™åˆ«å­—ï¼Œæ¯å¥è¯ä¸€è¡Œï¼Œç›´æ¥è¾“å‡ºä¸è¦è§£é‡Šï¼š
        \(text)
        """
        
        let body: [String: Any] = [
            "model": "qwen2:7b",
            "prompt": prompt,
            "stream": false,
            "options": ["temperature": 0.1, "num_predict": 2000, "num_ctx": 4096]
        ]
        
        do {
            request.httpBody = try JSONSerialization.data(withJSONObject: body)
            let (data, _) = try await URLSession.shared.data(for: request)
            if let json = try JSONSerialization.jsonObject(with: data) as? [String: Any],
               let response = json["response"] as? String {
                return response.trimmingCharacters(in: .whitespacesAndNewlines)
            }
        } catch {
            print("Ollamaæ¶¦è‰²å¤±è´¥: \(error)")
        }
        return nil
    }
    
    private func redistributeTimestamps(polishedText: String, originalSubtitles: [Subtitle]) -> [Subtitle] {
        guard !originalSubtitles.isEmpty else { return [] }
        
        // å…ˆæŒ‰æ¢è¡Œåˆ†å‰²ï¼Œç„¶åå†æŒ‰å¥å·ç­‰æ ‡ç‚¹åˆ†å‰²
        var lines: [String] = []
        let rawLines = polishedText.components(separatedBy: .newlines)
            .map { $0.trimmingCharacters(in: .whitespaces) }
            .filter { !$0.isEmpty }
        
        for line in rawLines {
            // æŒ‰å¥å·ã€é—®å·ã€æ„Ÿå¹å·åˆ†å‰²æ¯ä¸€è¡Œ
            let sentences = splitBySentence(line)
            lines.append(contentsOf: sentences)
        }
        
        guard !lines.isEmpty else { return originalSubtitles }
        
        let totalDuration = originalSubtitles.last!.endTime - originalSubtitles.first!.startTime
        let startTime = originalSubtitles.first!.startTime
        let totalChars = lines.reduce(0) { $0 + $1.count }
        var currentTime = startTime
        var result: [Subtitle] = []
        
        for line in lines {
            let lineDuration = totalDuration * Double(line.count) / Double(totalChars)
            result.append(Subtitle(text: line, startTime: currentTime, endTime: currentTime + lineDuration, isPolished: true))
            currentTime += lineDuration
        }
        return result
    }
    
    /// æŒ‰å¥å­åˆ†å‰²æ–‡æœ¬ï¼ˆå¥å·ã€é—®å·ã€æ„Ÿå¹å·ï¼‰
    private func splitBySentence(_ text: String) -> [String] {
        var sentences: [String] = []
        var current = ""
        
        for char in text {
            current.append(char)
            // é‡åˆ°å¥æœ«æ ‡ç‚¹å°±åˆ†å‰²
            if char == "ã€‚" || char == "ï¼Ÿ" || char == "ï¼" || char == "?" || char == "!" {
                let trimmed = current.trimmingCharacters(in: .whitespaces)
                if !trimmed.isEmpty {
                    sentences.append(trimmed)
                }
                current = ""
            }
        }
        
        // å¤„ç†æœ€åä¸€æ®µï¼ˆå¯èƒ½æ²¡æœ‰å¥æœ«æ ‡ç‚¹ï¼‰
        let trimmed = current.trimmingCharacters(in: .whitespaces)
        if !trimmed.isEmpty {
            sentences.append(trimmed)
        }
        
        return sentences
    }
    
    private func saveSubtitle(for audioURL: URL) async {
        let path = subtitlePath(for: audioURL)
        do {
            try FileManager.default.createDirectory(at: subtitleDirectory, withIntermediateDirectories: true)
            try generateSRT(subtitles).write(to: path, atomically: true, encoding: .utf8)
        } catch { print("ä¿å­˜å­—å¹•å¤±è´¥: \(error)") }
    }
    
    private func generateSRT(_ subtitles: [Subtitle]) -> String {
        var srt = ""
        for (i, sub) in subtitles.enumerated() {
            srt += "\(i+1)\n\(formatSRTTime(sub.startTime)) --> \(formatSRTTime(sub.endTime))\n\(sub.text)\n\n"
        }
        return srt
    }
    
    private func formatSRTTime(_ s: TimeInterval) -> String {
        String(format: "%02d:%02d:%02d,%03d", Int(s)/3600, (Int(s)%3600)/60, Int(s)%60, Int((s.truncatingRemainder(dividingBy: 1))*1000))
    }
    
    private func parseSRT(_ content: String) -> [Subtitle] {
        var subs: [Subtitle] = []
        for block in content.components(separatedBy: "\n\n") {
            let lines = block.components(separatedBy: "\n")
            guard lines.count >= 3 else { continue }
            let times = lines[1].components(separatedBy: " --> ")
            guard times.count == 2 else { continue }
            subs.append(Subtitle(text: lines[2...].joined(separator: "\n"), startTime: parseSRTTime(times[0]), endTime: parseSRTTime(times[1]), isPolished: true))
        }
        return subs
    }
    
    private func parseSRTTime(_ t: String) -> TimeInterval {
        let p = t.replacingOccurrences(of: ",", with: ".").components(separatedBy: ":")
        guard p.count == 3 else { return 0 }
        return (Double(p[0]) ?? 0) * 3600 + (Double(p[1]) ?? 0) * 60 + (Double(p[2]) ?? 0)
    }

    
    func deleteSubtitle(for audioURL: URL) {
        let fm = FileManager.default
        let fileName = audioURL.deletingPathExtension().lastPathComponent
        
        // åˆ é™¤æ–°æ ¼å¼æ–‡ä»¶
        let newPath = subtitlePath(for: audioURL)
        try? fm.removeItem(at: newPath)
        
        // åˆ é™¤æ‰€æœ‰æ—§æ ¼å¼æ–‡ä»¶ï¼ˆå¯èƒ½æœ‰å¤šä¸ªï¼‰
        if let contents = try? fm.contentsOfDirectory(at: subtitleDirectory, includingPropertiesForKeys: nil) {
            for file in contents {
                if file.pathExtension == "srt" && file.lastPathComponent.hasPrefix(fileName + "_") {
                    try? fm.removeItem(at: file)
                }
            }
        }
    }
    
    func switchModel(to modelId: String) {
        guard modelId != currentModelId else { return }
        currentModelId = modelId
        whisperKit = nil
        isModelLoaded = false
        Task { await loadModel() }
    }
    
    func loadModel() async {
        guard whisperKit == nil else { isModelLoaded = true; return }
        let selectedModel = AIModelManager.shared.selectedWhisperModel
        currentModelId = selectedModel
        processingProgress = "åŠ è½½æ¨¡å‹..."
        
        do {
            let fm = FileManager.default
            if !fm.fileExists(atPath: modelDirectory.path) {
                try fm.createDirectory(at: modelDirectory, withIntermediateDirectories: true)
            }
            
            let modelPath = whisperKitModelDirectory.appendingPathComponent("openai_whisper-\(selectedModel)")
            
            if fm.fileExists(atPath: modelPath.path) {
                print("ğŸ“¦ ä»æœ¬åœ°åŠ è½½æ¨¡å‹: \(modelPath.lastPathComponent)")
                whisperKit = try await WhisperKit(modelFolder: modelPath.path, verbose: false)
            } else {
                processingProgress = "ä¸‹è½½æ¨¡å‹ \(selectedModel)..."
                print("â¬‡ï¸ ä¸‹è½½æ¨¡å‹: \(selectedModel)")
                whisperKit = try await WhisperKit(model: selectedModel, downloadBase: modelDirectory, verbose: true)
            }
            isModelLoaded = true
            processingProgress = ""
            print("âœ… æ¨¡å‹åŠ è½½å®Œæˆ: \(selectedModel)")
            await AIModelManager.shared.checkWhisperModels()
        } catch {
            self.error = "æ¨¡å‹åŠ è½½å¤±è´¥: \(error.localizedDescription)"
            processingProgress = ""
            isModelLoaded = false
        }
    }
    
    func stopTranscription() { currentTask?.cancel(); currentTask = nil; streamingTask?.cancel(); streamingTask = nil; isProcessing = false; isStreamingMode = false; streamingReady = false; processingProgress = "" }
    func transcribe(audioURL: URL) async { startTranscription(audioURL: audioURL) }
    func seekAndTranscribe(to time: TimeInterval) { }
    
    // MARK: - æµå¼è½¬å†™æ¨¡å¼
    
    // ç¼“å­˜å®Œæ•´çš„åŸå§‹è½¬å†™ç»“æœ
    private var cachedRawSubtitles: [Subtitle] = []
    private var transcriptionComplete = false
    
    /// æ£€æŸ¥å­—å¹•æ˜¯å¦å®Œæ•´ï¼ˆæ˜¯å¦å·²å¤„ç†åˆ°éŸ³é¢‘æœ«å°¾ï¼‰
    private func isSubtitleComplete(for audioURL: URL, subtitles: [Subtitle]) async -> Bool {
        guard let lastSub = subtitles.last else { return false }
        
        let asset = AVURLAsset(url: audioURL)
        guard let duration = try? await asset.load(.duration) else { return false }
        let totalDuration = CMTimeGetSeconds(duration)
        
        let isComplete = lastSub.endTime >= totalDuration - 5
        print("ğŸ“Š å­—å¹•å®Œæ•´æ€§æ£€æŸ¥: æœ€åå­—å¹•ç»“æŸæ—¶é—´=\(formatTime(lastSub.endTime)), éŸ³é¢‘æ€»æ—¶é•¿=\(formatTime(totalDuration)), å®Œæ•´=\(isComplete)")
        
        // å¦‚æœæœ€åä¸€æ¡å­—å¹•çš„ç»“æŸæ—¶é—´æ¥è¿‘éŸ³é¢‘æ€»æ—¶é•¿ï¼ˆå·®è·å°äº5ç§’ï¼‰ï¼Œè®¤ä¸ºå·²å®Œæˆ
        return isComplete
    }
    
    /// å¼€å§‹æµå¼è½¬å†™ - æ”¯æŒæ–­ç‚¹ç»­ä¼ 
    func startStreamingTranscription(audioURL: URL, onReady: @escaping () -> Void) {
        currentAudioURL = audioURL
        subtitles = []
        fullTranscript = ""
        hasPreprocessedSubtitle = false
        isStreamingMode = true
        streamingReady = false
        processedEndTime = 0
        cachedRawSubtitles = []
        transcriptionComplete = false
        
        streamingTask = Task {
            defer {
                Task { @MainActor in
                    self.isProcessing = false
                }
            }
            
            // æ£€æŸ¥æ˜¯å¦æœ‰å·²ä¿å­˜çš„å­—å¹•ï¼ˆå¯èƒ½æ˜¯ä¸Šæ¬¡ä¸­æ–­çš„ï¼‰
            var resumeFromTime: TimeInterval = 0
            print("ğŸ” æ£€æŸ¥å­—å¹•æ–‡ä»¶: \(audioURL.lastPathComponent)")
            if loadSavedSubtitle(for: audioURL) {
                print("ğŸ“‚ æ‰¾åˆ°å·²ä¿å­˜çš„å­—å¹•ï¼Œå…± \(subtitles.count) æ¡")
                // æ£€æŸ¥å­—å¹•æ˜¯å¦å®Œæ•´
                if await isSubtitleComplete(for: audioURL, subtitles: subtitles) {
                    // å­—å¹•å®Œæ•´ï¼Œç›´æ¥ä½¿ç”¨
                    print("âœ… å­—å¹•å·²å®Œæ•´ï¼Œç›´æ¥ä½¿ç”¨")
                    processingProgress = "å·²åŠ è½½ä¿å­˜çš„å­—å¹•"
                    streamingReady = true
                    hasPreprocessedSubtitle = true
                    onReady()
                    return
                } else {
                    // å­—å¹•ä¸å®Œæ•´ï¼Œä»ä¸Šæ¬¡ä¸­æ–­çš„åœ°æ–¹ç»§ç»­
                    if let lastSub = subtitles.last {
                        // å¾€å‰æ¨10ç§’ï¼Œé˜²æ­¢æ¼æ‰å¥å­
                        resumeFromTime = max(0, lastSub.endTime - 10)
                        processedEndTime = lastSub.endTime
                        print("ğŸ“‚ æ£€æµ‹åˆ°æœªå®Œæˆçš„å­—å¹•ï¼Œä» \(formatTime(resumeFromTime)) ç»§ç»­å¤„ç†")
                    }
                    // å·²æœ‰å­—å¹•ï¼Œå¯ä»¥å…ˆå¼€å§‹æ’­æ”¾
                    streamingReady = true
                    onReady()
                }
            } else {
                print("ğŸ“‚ æ²¡æœ‰æ‰¾åˆ°å·²ä¿å­˜çš„å­—å¹•ï¼Œä»å¤´å¼€å§‹")
            }
            
            if !isModelLoaded || whisperKit == nil { await loadModel() }
            guard let whisper = whisperKit else { 
                error = "æ¨¡å‹æœªåŠ è½½"
                return 
            }
            
            isProcessing = true
            error = nil
            
            // è·å–éŸ³é¢‘æ€»æ—¶é•¿
            let asset = AVURLAsset(url: audioURL)
            guard let duration = try? await asset.load(.duration) else {
                error = "æ— æ³•è¯»å–éŸ³é¢‘"
                return
            }
            let totalDuration = CMTimeGetSeconds(duration)
            print("ğŸ¬ å¼€å§‹æµå¼è½¬å†™ï¼Œæ€»æ—¶é•¿: \(formatTime(totalDuration))")
            
            // æ¸è¿›å¼ chunkï¼š25ç§’ â†’ 30ç§’ â†’ 35ç§’ â†’ 40ç§’ï¼ˆæœ€å¤§ï¼‰
            // æ¯æ®µä¹‹é—´æœ‰ 5 ç§’é‡å ï¼Œé˜²æ­¢è¾¹ç•Œä¸¢å¤±æ–‡å­—
            let chunkSizes: [TimeInterval] = [25, 30, 35, 40]
            let overlapDuration: TimeInterval = 5  // é‡å æ—¶é—´
            var chunkIndex = 0
            var currentStart: TimeInterval = resumeFromTime
            var isFirstChunk = (resumeFromTime == 0)
            var lastChunkEndTime: TimeInterval = resumeFromTime  // ä¸Šä¸€æ®µçš„å®é™…ç»“æŸæ—¶é—´ï¼ˆä¸å«é‡å ï¼‰
            
            // å¾ªç¯å¤„ç†æ¯ä¸ªç‰‡æ®µ
            while currentStart < totalDuration && !Task.isCancelled && isStreamingMode {
                // è·å–å½“å‰ chunk å¤§å°ï¼ˆæ¸è¿›å¢åŠ ï¼‰
                let currentChunkSize = chunkSizes[min(chunkIndex, chunkSizes.count - 1)]
                // å®é™…æå–çš„ç»“æŸæ—¶é—´ï¼ˆåŒ…å«é‡å ï¼‰
                let extractEnd = min(currentStart + currentChunkSize, totalDuration)
                // è¿™ä¸€æ®µçš„æœ‰æ•ˆç»“æŸæ—¶é—´ï¼ˆä¸å«é‡å ï¼Œç”¨äºä¸‹ä¸€æ®µçš„èµ·å§‹ï¼‰
                let effectiveEnd = min(currentStart + currentChunkSize - overlapDuration, totalDuration)
                
                if isFirstChunk {
                    processingProgress = "è½¬å†™å‰\(Int(currentChunkSize))ç§’..."
                } else {
                    processingProgress = "è½¬å†™ \(formatTime(currentStart))-\(formatTime(extractEnd))..."
                }
                
                print("ğŸ”„ è½¬å†™ \(formatTime(currentStart)) - \(formatTime(extractEnd)) (chunk \(Int(currentChunkSize))ç§’, æœ‰æ•ˆåˆ° \(formatTime(effectiveEnd)))")
                
                // æå–å¹¶è½¬å†™è¿™ä¸€æ®µï¼ˆåŒ…å«é‡å éƒ¨åˆ†ï¼‰
                guard let chunkSubs = await transcribeAudioChunk(
                    audioURL: audioURL,
                    start: currentStart,
                    end: extractEnd,
                    whisper: whisper
                ) else {
                    if isFirstChunk {
                        error = "è½¬å†™å¤±è´¥"
                        return
                    }
                    currentStart = effectiveEnd
                    chunkIndex += 1
                    continue
                }
                
                guard !Task.isCancelled else { return }
                
                // æ¶¦è‰²è¿™ä¸€æ®µ
                if isFirstChunk {
                    processingProgress = "æ¶¦è‰²å­—å¹•ä¸­..."
                }
                
                let rawText = chunkSubs.map { $0.text }.joined()
                var polishedSubs = chunkSubs
                
                if let polishedText = await polishSegment(rawText), !chunkSubs.isEmpty {
                    polishedSubs = redistributeTimestamps(polishedText: polishedText, originalSubtitles: chunkSubs)
                }
                
                // æ™ºèƒ½åˆå¹¶å­—å¹•ï¼ˆå¤„ç†é‡å éƒ¨åˆ†ï¼‰
                if subtitles.isEmpty {
                    subtitles = polishedSubs
                } else {
                    // æ‰¾åˆ°é‡å åŒºåŸŸçš„è¾¹ç•Œ
                    let overlapBoundary = lastChunkEndTime
                    
                    // ä»æ–°å­—å¹•ä¸­åªå–é‡å è¾¹ç•Œä¹‹åçš„éƒ¨åˆ†
                    // ä½†è¦ä¿ç•™ä¸€äº›é‡å ä»¥ç¡®ä¿ä¸ä¸¢å¤±è¾¹ç•Œå¤„çš„æ–‡å­—
                    let newSubs = polishedSubs.filter { sub in
                        // å¦‚æœå­—å¹•çš„ä¸­ç‚¹åœ¨è¾¹ç•Œä¹‹åï¼Œå°±ä¿ç•™
                        let midPoint = (sub.startTime + sub.endTime) / 2
                        return midPoint > overlapBoundary - 1  // å…è®¸1ç§’çš„å®¹å·®
                    }
                    
                    // ç§»é™¤æ—§å­—å¹•ä¸­ä¸æ–°å­—å¹•é‡å çš„éƒ¨åˆ†
                    if let firstNewSub = newSubs.first {
                        subtitles.removeAll { $0.startTime >= firstNewSub.startTime - 0.5 }
                    }
                    
                    subtitles.append(contentsOf: newSubs)
                    
                    // æŒ‰æ—¶é—´æ’åºå¹¶å»é‡
                    subtitles.sort { $0.startTime < $1.startTime }
                    subtitles = deduplicateSubtitles(subtitles)
                }
                
                cachedRawSubtitles.append(contentsOf: chunkSubs)
                lastChunkEndTime = effectiveEnd
                processedEndTime = extractEnd
                
                // æ¯å¤„ç†å®Œä¸€æ®µå°±ä¿å­˜ï¼Œé˜²æ­¢ä¸­é€”å…³é—­ä¸¢å¤±
                await saveSubtitle(for: audioURL)
                
                print("âœ… å·²å¤„ç†åˆ° \(formatTime(extractEnd))ï¼Œå…± \(subtitles.count) æ¡å­—å¹•")
                
                // ç¬¬ä¸€æ®µå¤„ç†å®Œåï¼Œé€šçŸ¥å¯ä»¥å¼€å§‹æ’­æ”¾
                if isFirstChunk {
                    streamingReady = true
                    processingProgress = ""
                    print("âœ… å‰\(Int(currentChunkSize))ç§’å‡†å¤‡å®Œæˆï¼Œå¼€å§‹æ’­æ”¾")
                    onReady()
                    isFirstChunk = false
                }
                
                // ä¸‹ä¸€æ®µä»æœ‰æ•ˆç»“æŸæ—¶é—´å¼€å§‹ï¼ˆè¿™æ ·ä¼šæœ‰é‡å ï¼‰
                currentStart = effectiveEnd
                chunkIndex += 1
            }
            
            // å…¨éƒ¨å¤„ç†å®Œæˆ
            if !Task.isCancelled {
                transcriptionComplete = true
                await saveSubtitle(for: audioURL)
                hasPreprocessedSubtitle = true
                fullTranscript = subtitles.map { $0.text }.joined(separator: " ")
                processingProgress = ""
                print("âœ… æµå¼è½¬å†™å®Œæˆï¼Œå…± \(subtitles.count) æ¡å­—å¹•")
            }
        }
    }
    
    /// è½¬å†™æŒ‡å®šæ—¶é—´æ®µçš„éŸ³é¢‘ï¼ˆä½¿ç”¨ AVAssetReader æå–éŸ³é¢‘æ•°æ®ï¼‰
    private func transcribeAudioChunk(audioURL: URL, start: TimeInterval, end: TimeInterval, whisper: WhisperKit) async -> [Subtitle]? {
        do {
            // åˆ›å»ºä¸´æ—¶ WAV æ–‡ä»¶
            let tempURL = FileManager.default.temporaryDirectory
                .appendingPathComponent("chunk_\(UUID().uuidString).wav")
            
            // æå–éŸ³é¢‘ç‰‡æ®µåˆ° WAV æ–‡ä»¶
            let success = await extractAudioToWAV(from: audioURL, to: tempURL, start: start, end: end)
            guard success else {
                print("âŒ æå–éŸ³é¢‘ç‰‡æ®µå¤±è´¥")
                return nil
            }
            
            defer { try? FileManager.default.removeItem(at: tempURL) }
            
            let options = DecodingOptions(
                task: .transcribe,
                language: "zh",
                usePrefillPrompt: true,
                skipSpecialTokens: true,
                withoutTimestamps: false,
                wordTimestamps: true
            )
            
            let results = try await whisper.transcribe(audioPath: tempURL.path, decodeOptions: options)
            
            var subtitles: [Subtitle] = []
            for result in results {
                for segment in result.segments {
                    var text = segment.text.trimmingCharacters(in: .whitespacesAndNewlines)
                    if !text.isEmpty {
                        text = convertToSimplified(text)
                        // è°ƒæ•´æ—¶é—´æˆ³ï¼šåŠ ä¸Šèµ·å§‹åç§»
                        subtitles.append(Subtitle(
                            text: text,
                            startTime: TimeInterval(segment.start) + start,
                            endTime: TimeInterval(segment.end) + start,
                            isPolished: false
                        ))
                    }
                }
            }
            return subtitles
        } catch {
            print("âŒ è½¬å†™chunkå¤±è´¥: \(error)")
            return nil
        }
    }
    
    /// ä½¿ç”¨ AVAssetReader æå–éŸ³é¢‘ç‰‡æ®µåˆ° WAV æ–‡ä»¶
    private func extractAudioToWAV(from sourceURL: URL, to destURL: URL, start: TimeInterval, end: TimeInterval) async -> Bool {
        let asset = AVURLAsset(url: sourceURL)
        
        do {
            // åŠ è½½éŸ³é¢‘è½¨é“
            let tracks = try await asset.loadTracks(withMediaType: .audio)
            guard let audioTrack = tracks.first else {
                print("âŒ æ²¡æœ‰æ‰¾åˆ°éŸ³é¢‘è½¨é“")
                return false
            }
            
            // åˆ›å»º reader
            let reader = try AVAssetReader(asset: asset)
            
            // è®¾ç½®æ—¶é—´èŒƒå›´
            let startTime = CMTime(seconds: start, preferredTimescale: 44100)
            let endTime = CMTime(seconds: end, preferredTimescale: 44100)
            reader.timeRange = CMTimeRange(start: startTime, end: endTime)
            
            // è¾“å‡ºè®¾ç½®ï¼š16kHz å•å£°é“ PCMï¼ˆWhisperKit éœ€è¦çš„æ ¼å¼ï¼‰
            let outputSettings: [String: Any] = [
                AVFormatIDKey: kAudioFormatLinearPCM,
                AVSampleRateKey: 16000,
                AVNumberOfChannelsKey: 1,
                AVLinearPCMBitDepthKey: 16,
                AVLinearPCMIsFloatKey: false,
                AVLinearPCMIsBigEndianKey: false
            ]
            
            let readerOutput = AVAssetReaderTrackOutput(track: audioTrack, outputSettings: outputSettings)
            reader.add(readerOutput)
            
            guard reader.startReading() else {
                print("âŒ æ— æ³•å¼€å§‹è¯»å–: \(reader.error?.localizedDescription ?? "æœªçŸ¥é”™è¯¯")")
                return false
            }
            
            // æ”¶é›†æ‰€æœ‰éŸ³é¢‘æ•°æ®
            var audioData = Data()
            while let sampleBuffer = readerOutput.copyNextSampleBuffer() {
                if let blockBuffer = CMSampleBufferGetDataBuffer(sampleBuffer) {
                    var length = 0
                    var dataPointer: UnsafeMutablePointer<Int8>?
                    CMBlockBufferGetDataPointer(blockBuffer, atOffset: 0, lengthAtOffsetOut: nil, totalLengthOut: &length, dataPointerOut: &dataPointer)
                    if let dataPointer = dataPointer {
                        audioData.append(UnsafeBufferPointer(start: dataPointer, count: length))
                    }
                }
            }
            
            guard reader.status == .completed else {
                print("âŒ è¯»å–æœªå®Œæˆ: \(reader.error?.localizedDescription ?? "æœªçŸ¥é”™è¯¯")")
                return false
            }
            
            // å†™å…¥ WAV æ–‡ä»¶
            let wavData = createWAVFile(from: audioData, sampleRate: 16000, channels: 1, bitsPerSample: 16)
            try wavData.write(to: destURL)
            
            return true
        } catch {
            print("âŒ æå–éŸ³é¢‘å¤±è´¥: \(error)")
            return false
        }
    }
    
    /// åˆ›å»º WAV æ–‡ä»¶æ•°æ®
    private func createWAVFile(from pcmData: Data, sampleRate: Int, channels: Int, bitsPerSample: Int) -> Data {
        var wavData = Data()
        
        let byteRate = sampleRate * channels * bitsPerSample / 8
        let blockAlign = channels * bitsPerSample / 8
        let dataSize = pcmData.count
        let fileSize = 36 + dataSize
        
        // RIFF header
        wavData.append("RIFF".data(using: .ascii)!)
        wavData.append(withUnsafeBytes(of: UInt32(fileSize).littleEndian) { Data($0) })
        wavData.append("WAVE".data(using: .ascii)!)
        
        // fmt chunk
        wavData.append("fmt ".data(using: .ascii)!)
        wavData.append(withUnsafeBytes(of: UInt32(16).littleEndian) { Data($0) })  // chunk size
        wavData.append(withUnsafeBytes(of: UInt16(1).littleEndian) { Data($0) })   // PCM format
        wavData.append(withUnsafeBytes(of: UInt16(channels).littleEndian) { Data($0) })
        wavData.append(withUnsafeBytes(of: UInt32(sampleRate).littleEndian) { Data($0) })
        wavData.append(withUnsafeBytes(of: UInt32(byteRate).littleEndian) { Data($0) })
        wavData.append(withUnsafeBytes(of: UInt16(blockAlign).littleEndian) { Data($0) })
        wavData.append(withUnsafeBytes(of: UInt16(bitsPerSample).littleEndian) { Data($0) })
        
        // data chunk
        wavData.append("data".data(using: .ascii)!)
        wavData.append(withUnsafeBytes(of: UInt32(dataSize).littleEndian) { Data($0) })
        wavData.append(pcmData)
        
        return wavData
    }
    
    /// åœæ­¢æµå¼è½¬å†™
    func stopStreamingTranscription() {
        isStreamingMode = false
        streamingTask?.cancel()
        streamingTask = nil
    }
    
    /// åˆå§‹åŒ–è½¬å†™ï¼šåªè½¬å†™å‰ N ç§’å¹¶ä¿å­˜ï¼Œç”¨äºæ‰¹é‡é¢„å¤„ç†
    func initializeTranscription(audioURL: URL, duration: TimeInterval = 60) async throws -> Bool {
        // å¦‚æœå·²æœ‰å­—å¹•ï¼Œè·³è¿‡
        if hasSubtitle(for: audioURL) {
            print("â­ï¸ å·²æœ‰å­—å¹•ï¼Œè·³è¿‡: \(audioURL.lastPathComponent)")
            return true
        }
        
        // ç¡®ä¿æ¨¡å‹å·²åŠ è½½
        if !isModelLoaded || whisperKit == nil {
            await loadModel()
        }
        
        guard let whisper = whisperKit else {
            throw NSError(domain: "WhisperService", code: -1, userInfo: [NSLocalizedDescriptionKey: "æ¨¡å‹æœªåŠ è½½"])
        }
        
        print("ğŸš€ åˆå§‹åŒ–è½¬å†™: \(audioURL.lastPathComponent) (å‰\(Int(duration))ç§’)")
        
        // è·å–éŸ³é¢‘å®é™…æ—¶é•¿
        let asset = AVURLAsset(url: audioURL)
        let assetDuration = try await asset.load(.duration)
        let totalDuration = CMTimeGetSeconds(assetDuration)
        let actualDuration = min(duration, totalDuration)
        
        // è½¬å†™å‰ N ç§’
        guard let rawSubs = await transcribeAudioChunk(
            audioURL: audioURL,
            start: 0,
            end: actualDuration,
            whisper: whisper
        ) else {
            throw NSError(domain: "WhisperService", code: -2, userInfo: [NSLocalizedDescriptionKey: "è½¬å†™å¤±è´¥"])
        }
        
        // æ¶¦è‰²
        let rawText = rawSubs.map { $0.text }.joined()
        var polishedSubs = rawSubs
        
        if let polishedText = await polishSegment(rawText), !rawSubs.isEmpty {
            polishedSubs = redistributeTimestamps(polishedText: polishedText, originalSubtitles: rawSubs)
        }
        
        // ä¸´æ—¶ä¿å­˜åˆ° subtitles ä»¥ä¾¿ saveSubtitle ä½¿ç”¨
        let originalSubs = subtitles
        subtitles = polishedSubs
        await saveSubtitle(for: audioURL)
        subtitles = originalSubs  // æ¢å¤åŸæ¥çš„å­—å¹•
        
        print("âœ… åˆå§‹åŒ–å®Œæˆ: \(audioURL.lastPathComponent), å…± \(polishedSubs.count) æ¡å­—å¹•")
        return true
    }
    
    private func formatTime(_ s: Double) -> String { String(format: "%d:%02d", Int(s)/60, Int(s)%60) }
    private func convertToSimplified(_ text: String) -> String {
        let m = NSMutableString(string: text)
        CFStringTransform(m, nil, "Traditional-Simplified" as CFString, false)
        return m as String
    }
    
    /// å»é™¤é‡å¤çš„å­—å¹•ï¼ˆåŸºäºæ–‡æœ¬ç›¸ä¼¼åº¦å’Œæ—¶é—´é‡å ï¼‰
    private func deduplicateSubtitles(_ subs: [Subtitle]) -> [Subtitle] {
        guard subs.count > 1 else { return subs }
        
        var result: [Subtitle] = []
        for sub in subs {
            // æ£€æŸ¥æ˜¯å¦ä¸å·²æœ‰å­—å¹•é‡å¤
            let isDuplicate = result.contains { existing in
                // æ—¶é—´é‡å æ£€æŸ¥
                let timeOverlap = existing.startTime < sub.endTime && sub.startTime < existing.endTime
                if !timeOverlap { return false }
                
                // æ–‡æœ¬ç›¸ä¼¼åº¦æ£€æŸ¥ï¼ˆå¦‚æœæ–‡æœ¬ç›¸ä¼¼åº¦è¶…è¿‡70%ï¼Œè®¤ä¸ºæ˜¯é‡å¤ï¼‰
                let similarity = textSimilarity(existing.text, sub.text)
                return similarity > 0.7
            }
            
            if !isDuplicate {
                result.append(sub)
            }
        }
        return result
    }
    
    /// è®¡ç®—ä¸¤ä¸ªå­—ç¬¦ä¸²çš„ç›¸ä¼¼åº¦ï¼ˆ0-1ï¼‰
    private func textSimilarity(_ s1: String, _ s2: String) -> Double {
        if s1 == s2 { return 1.0 }
        if s1.isEmpty || s2.isEmpty { return 0.0 }
        
        // ç®€å•çš„å­—ç¬¦é‡å ç‡è®¡ç®—
        let set1 = Set(s1)
        let set2 = Set(s2)
        let intersection = set1.intersection(set2).count
        let union = set1.union(set2).count
        
        return Double(intersection) / Double(union)
    }
}
